{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Document QA System\n",
    "\n",
    "## Project Overview\n",
    "This project builds a Question-Answering system that can query across multiple PDF documents.\n",
    "It allows you to:\n",
    "- Load multiple PDF files simultaneously\n",
    "- Query information across all documents\n",
    "- Get answers with source attribution (which document and page)\n",
    "- Compare information from different sources\n",
    "\n",
    "## Use Cases\n",
    "- Research: Compare information across multiple research papers\n",
    "- Legal: Search through multiple contracts or legal documents\n",
    "- Business: Analyze multiple reports or policies\n",
    "\n",
    "## What You'll Learn\n",
    "1. Loading multiple documents with metadata\n",
    "2. Combining documents from different sources in one vector store\n",
    "3. Source attribution and tracking\n",
    "4. Cross-document information retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(\"âœ… Environment loaded\")\n",
    "print(f\"OpenAI API Key found: {'OPENAI_API_KEY' in os.environ}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "print(f\"Environment loaded: {'OPENAI_API_KEY' in os.environ}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document loading and processing\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Embeddings and vector store\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# LLM and chains\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_classic.chains.retrieval_qa.base import RetrievalQA\n",
    "\n",
    "# Utilities\n",
    "from typing import List\n",
    "import glob\n",
    "\n",
    "print(\"âœ… All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Multiple PDF Documents\n",
    "\n",
    "For this demo, we'll load all PDF files from a directory.\n",
    "Each document will retain its source file information in metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multiple_pdfs(pdf_paths: List[str]):\n",
    "    \"\"\"\n",
    "    Load multiple PDF files and combine their documents.\n",
    "    \n",
    "    Args:\n",
    "        pdf_paths: List of file paths to PDF documents\n",
    "        \n",
    "    Returns:\n",
    "        List of document objects with metadata\n",
    "    \"\"\"\n",
    "    all_documents = []\n",
    "    \n",
    "    for pdf_path in pdf_paths:\n",
    "        # Load each PDF\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents = loader.load()\n",
    "        \n",
    "        # Add custom metadata to track source file\n",
    "        for doc in documents:\n",
    "            # Extract just the filename (not full path)\n",
    "            doc.metadata['source_file'] = os.path.basename(pdf_path)\n",
    "        \n",
    "        all_documents.extend(documents)\n",
    "        print(f\"âœ… Loaded {len(documents)} pages from {os.path.basename(pdf_path)}\")\n",
    "    \n",
    "    return all_documents\n",
    "\n",
    "# Example: Load PDFs from the parent RAG folder\n",
    "# Modify this list to include your PDF files\n",
    "pdf_files = [\n",
    "    \"../RAG/llm_fundamentals.pdf\",\n",
    "    # Add more PDF paths here\n",
    "    # \"../RAG/another_document.pdf\",\n",
    "    # \"../RAG/third_document.pdf\",\n",
    "]\n",
    "\n",
    "# Load all documents\n",
    "all_documents = load_multiple_pdfs(pdf_files)\n",
    "print(f\"\\nðŸ“š Total documents loaded: {len(all_documents)} pages from {len(pdf_files)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Split Documents into Chunks\n",
    "\n",
    "We split the documents while preserving the source metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,        # Size of each chunk\n",
    "    chunk_overlap=50,      # Overlap between chunks to maintain context\n",
    "    length_function=len,   # Function to measure chunk length\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # Split on paragraphs first, then sentences\n",
    ")\n",
    "\n",
    "# Split all documents\n",
    "chunks = text_splitter.split_documents(all_documents)\n",
    "\n",
    "print(f\"âœ… Split {len(all_documents)} pages into {len(chunks)} chunks\")\n",
    "print(f\"\\nSample chunk with metadata:\")\n",
    "print(f\"Source File: {chunks[0].metadata.get('source_file', 'Unknown')}\")\n",
    "print(f\"Page: {chunks[0].metadata.get('page', 'Unknown')}\")\n",
    "print(f\"Content Preview: {chunks[0].page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Embeddings and Vector Store\n",
    "\n",
    "Store all chunks in a single vector store for unified search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embedding model\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Create vector store from all chunks\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"multi_document_collection\"\n",
    ")\n",
    "\n",
    "print(f\"âœ… Vector store created with {vectorstore._collection.count()} chunks\")\n",
    "print(f\"   Chunks from {len(pdf_files)} different documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7,  # Balanced creativity and accuracy\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "print(\"âœ… LLM initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Create Multi-Document QA Chain\n",
    "\n",
    "This chain will retrieve relevant chunks from ANY of the loaded documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create QA chain with MMR retrieval for diverse results\n",
    "multi_doc_qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # Put all retrieved context in the prompt\n",
    "    retriever=vectorstore.as_retriever(\n",
    "        search_type=\"mmr\",  # Maximum Marginal Relevance for diverse results\n",
    "        search_kwargs={\n",
    "            \"k\": 5,          # Return top 5 chunks\n",
    "            \"fetch_k\": 20    # Consider top 20 for diversity selection\n",
    "        }\n",
    "    ),\n",
    "    return_source_documents=True  # Return source chunks for attribution\n",
    ")\n",
    "\n",
    "print(\"âœ… Multi-Document QA Chain created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Query Across Multiple Documents\n",
    "\n",
    "Now we can ask questions and get answers from any of the loaded documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_multi_documents(question: str):\n",
    "    \"\"\"\n",
    "    Query the multi-document QA system and display results with source attribution.\n",
    "    \n",
    "    Args:\n",
    "        question: The question to ask\n",
    "    \"\"\"\n",
    "    # Get answer from the chain\n",
    "    result = multi_doc_qa_chain.invoke({\"query\": question})\n",
    "    \n",
    "    # Display question and answer\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"QUESTION: {question}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    print(f\"ANSWER:\\n{result['result']}\\n\")\n",
    "    \n",
    "    # Display sources with file and page information\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"SOURCES ({len(result['source_documents'])} chunks):\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    for i, doc in enumerate(result['source_documents'], 1):\n",
    "        source_file = doc.metadata.get('source_file', 'Unknown')\n",
    "        page = doc.metadata.get('page', 'Unknown')\n",
    "        \n",
    "        print(f\"Source {i}: {source_file} (Page {page})\")\n",
    "        print(f\"   Content: {doc.page_content[:150]}...\")\n",
    "        print()\n",
    "\n",
    "# Example query\n",
    "query_multi_documents(\"What is LoRA and how does it work?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Try More Questions\n",
    "\n",
    "Test with different types of questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question about a specific topic\n",
    "query_multi_documents(\"What are the different types of attention mechanisms?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative question (if you have multiple documents)\n",
    "query_multi_documents(\"Compare the approaches to fine-tuning discussed in the documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Filter by Source Document (Optional)\n",
    "\n",
    "Query specific documents only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_specific_document(question: str, source_file: str):\n",
    "    \"\"\"\n",
    "    Query a specific document by filtering on source_file metadata.\n",
    "    \n",
    "    Args:\n",
    "        question: The question to ask\n",
    "        source_file: The filename to search in\n",
    "    \"\"\"\n",
    "    # Create retriever with metadata filter\n",
    "    filtered_retriever = vectorstore.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\n",
    "            \"k\": 5,\n",
    "            \"fetch_k\": 20,\n",
    "            \"filter\": {\"source_file\": source_file}  # Filter by source file\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Create temporary chain with filtered retriever\n",
    "    filtered_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=filtered_retriever,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "    \n",
    "    # Get answer\n",
    "    result = filtered_chain.invoke({\"query\": question})\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"FILTERED QUERY (Document: {source_file})\")\n",
    "    print(f\"QUESTION: {question}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    print(f\"ANSWER:\\n{result['result']}\\n\")\n",
    "\n",
    "# Example: Query only the llm_fundamentals.pdf\n",
    "query_specific_document(\n",
    "    \"What is attention mechanism?\",\n",
    "    \"llm_fundamentals.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What You've Built:\n",
    "- âœ… Multi-document loading system with metadata tracking\n",
    "- âœ… Unified vector store for cross-document search\n",
    "- âœ… QA system with source attribution (file + page)\n",
    "- âœ… Document-specific filtering capability\n",
    "\n",
    "### Key Concepts Learned:\n",
    "1. **Metadata Management**: Tracking source files and pages\n",
    "2. **Document Combination**: Merging multiple sources in one vector store\n",
    "3. **Source Attribution**: Showing which document provided the answer\n",
    "4. **Filtered Retrieval**: Querying specific documents\n",
    "\n",
    "### Next Steps:\n",
    "- Try with 3+ different PDF documents\n",
    "- Experiment with different chunk sizes for various document types\n",
    "- Add more metadata fields (author, date, category)\n",
    "- Implement document comparison queries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLNotebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
