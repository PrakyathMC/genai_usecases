{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5baf01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Variable loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing import List, Tuple, Dict\n",
    "import numpy as np\n",
    "\n",
    "# load dotenv\n",
    "load_dotenv()\n",
    "print(\"Environment Variable loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd19be72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge base has 8 documents.\n",
      "\n",
      "Sample Example Document:\n",
      "Machine learning is a subset of artificial intelligence that enables computers to learn from data without explicit programming. It uses algorithms to identify patterns and make predictions.\n"
     ]
    }
   ],
   "source": [
    "#sample knowledge base\n",
    "knowledge_base = [ \"Machine learning is a subset of artificial intelligence that enables computers to learn from data without explicit programming. It uses algorithms to identify patterns and make predictions.\",\n",
    "    \n",
    "    \"Deep learning is a type of machine learning that uses neural networks with multiple layers. It's particularly effective for image recognition, natural language processing, and complex pattern recognition tasks.\",\n",
    "    \n",
    "    \"Natural Language Processing (NLP) is a field of AI that focuses on the interaction between computers and human language. It enables machines to understand, interpret, and generate human language.\",\n",
    "    \n",
    "    \"Embeddings are numerical representations of text that capture semantic meaning. Similar texts have similar embedding vectors, which enables semantic search and similarity comparison.\",\n",
    "    \n",
    "    \"RAG (Retrieval Augmented Generation) combines information retrieval with text generation. It retrieves relevant context from a knowledge base and uses it to generate more accurate and informed responses.\",\n",
    "    \n",
    "    \"OpenAI's GPT models are large language models trained on diverse internet text. They can perform various tasks like text generation, summarization, translation, and question answering.\",\n",
    "    \n",
    "    \"Vector databases store embeddings and enable fast similarity search. Popular options include Chroma, Pinecone, Weaviate, and FAISS. They're essential for production RAG systems.\",\n",
    "    \n",
    "    \"Fine-tuning is the process of adapting a pre-trained model to a specific task by training it on domain-specific data. It's useful when you need specialized behavior beyond what prompting can achieve.\"\n",
    "]\n",
    "\n",
    "print(f\"Knowledge base has {len(knowledge_base)} documents.\")\n",
    "print(f\"\\nSample Example Document:\\n{knowledge_base[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00d13212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created embeddings with shape: (8, 384)\n",
      "Each document is respresented as a 384-dimensional vector.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "def create_embeddings(texts:List[str], model: str=\"all-MiniLM-L6-v2\") -> np.ndarray:\n",
    "    \"\"\"args:\n",
    "    texts: List of text data to be embedded\n",
    "    model: Model name from sentence transformers\n",
    "    \n",
    "    Returns:\n",
    "    NumPy array of embeddings (shape:[num_texts, embedding_dimension])\n",
    "    \"\"\"\n",
    "    model = SentenceTransformer(model)\n",
    "    embeddings = model.encode(texts)\n",
    "    return embeddings\n",
    "\n",
    "# Call function to create embeddings\n",
    "kb_embeddings = create_embeddings(knowledge_base)\n",
    "\n",
    "print(f\"Created embeddings with shape: {kb_embeddings.shape}\")\n",
    "print(f\"Each document is respresented as a {kb_embeddings.shape[1]}-dimensional vector.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2de9df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the meaning of deep learning?\n",
      "\n",
      "Result 1 (similarity: 0.7687):\n",
      "Deep learning is a type of machine learning that uses neural networks with multiple layers. It's particularly effective for image recognition, natural language processing, and complex pattern recognition tasks.\n",
      "\n",
      "Result 2 (similarity: 0.5162):\n",
      "Machine learning is a subset of artificial intelligence that enables computers to learn from data without explicit programming. It uses algorithms to identify patterns and make predictions.\n",
      "\n",
      "Result 3 (similarity: 0.3774):\n",
      "Natural Language Processing (NLP) is a field of AI that focuses on the interaction between computers and human language. It enables machines to understand, interpret, and generate human language.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def retrieve_relevant_docs(\n",
    "    query: str,\n",
    "    knowledge_base: List[str],\n",
    "    kb_embeddings: np.ndarray,\n",
    "    top_k: int=3) -> List[Tuple[str, float]]:\n",
    "\n",
    "    \"\"\"Args:\n",
    "    query: User's Question\n",
    "    knowledge_base: List of documet texts\n",
    "    kb_embeddings: NumPy array of knowledge base embeddings\n",
    "    top_k: Number of top relevant documents to retrieve\n",
    "    \"\"\"\n",
    "\n",
    "    # Create embeddings for query\n",
    "    query_embedding = create_embeddings([query])\n",
    "\n",
    "    # create similarity score between query and knowledge base\n",
    "    similarities = cosine_similarity(query_embedding, kb_embeddings)[0] \n",
    "\n",
    "    # get top_k indices \n",
    "    top_k_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "\n",
    "    # return document with similarity scores\n",
    "    results = [(knowledge_base[i], similarities[i]) for i in top_k_indices]\n",
    "    return results\n",
    "\n",
    "# call function to retrieve relevant documents\n",
    "query = \"What is the meaning of deep learning?\"\n",
    "relevant_docs = retrieve_relevant_docs(query, knowledge_base, kb_embeddings, top_k=3)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "for i, (doc, score) in enumerate(relevant_docs, 1):\n",
    "    print(f\"Result {i} (similarity: {score:.4f}):\")\n",
    "    print(f\"{doc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e20d1a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is deep learning and what is it used for?\n",
      "\n",
      "Answer:\n",
      "Deep learning is a type of machine learning that uses neural networks with multiple layers. It is particularly effective for tasks such as image recognition, natural language processing, and complex pattern recognition.\n",
      "\n",
      "Tokens used: 205\n",
      "\n",
      "Sources used (similarity scores):\n",
      "1. [0.825] Deep learning is a type of machine learning that uses neural networks with multi...\n",
      "2. [0.507] Machine learning is a subset of artificial intelligence that enables computers t...\n",
      "3. [0.379] Natural Language Processing (NLP) is a field of AI that focuses on the interacti...\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def generate_answer(\n",
    "    query: str,\n",
    "    context_docs: List[Tuple[str, float]],\n",
    "    model: str = \"gpt-4o-mini\") -> Dict[str, any]:\n",
    "\n",
    "    \"\"\"Args:\n",
    "    query: User's question\n",
    "    context_docs: Retrieved documents with similarity scores\n",
    "    model : OpenAI model name\n",
    "    \n",
    "    Returns: \n",
    "    Dictionary with answers and metadata\n",
    "    \"\"\"\n",
    "\n",
    "    # instantiate OpenAI client\n",
    "    client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "    # Prepare context by concatenating retrieved documents\n",
    "    context = \"\\n\\n\".join([doc for doc, _ in context_docs])\n",
    "\n",
    "    # Create prompt with context and query\n",
    "    system_prompt = \"\"\"You are a helpful AI assistant. Answer the user's question based on the provided context. \n",
    "If the context doesn't contain relevant information, say so rather than making up an answer.\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"Context: {context}\n",
    "\n",
    "    Question: {query}\n",
    "\n",
    "    Answer based on the above context: \"\"\"\n",
    "\n",
    "    # call openai chat completion\n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = [\n",
    "            {\"role\": \"system\" , \"content\": system_prompt},\n",
    "            {\"role\": \"user\" , \"content\": user_prompt}\n",
    "        ],\n",
    "\n",
    "        temperature = 0.6,\n",
    "        max_tokens = 300\n",
    "    )\n",
    "\n",
    "    return{\n",
    "        \"answer\": response.choices[0].message.content,\n",
    "        \"tokens_used\": response.usage.total_tokens,\n",
    "        \"sources\": [doc for doc, _ in context_docs],\n",
    "        \"similarity_scores\":[score for _, score in context_docs]\n",
    "    }\n",
    "\n",
    "# call function to generate answer\n",
    "query = \"What is deep learning and what is it used for?\"\n",
    "relevant_docs = retrieve_relevant_docs(query, knowledge_base, kb_embeddings, top_k=3)\n",
    "result = generate_answer(query, relevant_docs)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"Answer:\\n{result['answer']}\\n\")\n",
    "print(f\"Tokens used: {result['tokens_used']}\")\n",
    "print(f\"\\nSources used (similarity scores):\")\n",
    "for i, (source, score) in enumerate(zip(result['sources'], result['similarity_scores']), 1):\n",
    "    print(f\"{i}. [{score:.3f}] {source[:80]}...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913fb5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLNotebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
